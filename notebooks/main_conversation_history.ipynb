{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfrNeFuj6XGt"
      },
      "source": [
        "## 1. Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mw01kLe7RkCO"
      },
      "outputs": [],
      "source": [
        "# !pip install -U langchain-community\n",
        "# !pip install sentence-transformers\n",
        "# !pip install faiss-cpu\n",
        "# !pip install --upgrade langchain\n",
        "# !pip install fitz\n",
        "# !pip install PyMuPDF\n",
        "# !pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rt-p2YyLRqBJ"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "\n",
        "import faiss\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "import fitz\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from groq import Groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9g3BwfW6d9k"
      },
      "source": [
        "## 2. Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gB67f2VkSPRo"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def extract_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from a single PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    document = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text(\"text\")\n",
        "    return text\n",
        "\n",
        "def extract_texts_from_pdfs(pdf_paths):\n",
        "    \"\"\"\n",
        "    Extract text from each PDF file in the list and create Document objects.\n",
        "\n",
        "    Args:\n",
        "        pdf_paths (list of str): List of paths to PDF files.\n",
        "\n",
        "    Returns:\n",
        "        list of Document: List of Document objects containing the extracted text.\n",
        "    \"\"\"\n",
        "    docs = []\n",
        "    for pdf_path in pdf_paths:\n",
        "        text = extract_text(pdf_path)\n",
        "        doc = Document(page_content=text, metadata={\"source\": pdf_path})\n",
        "        docs.append(doc)\n",
        "    return docs\n",
        "\n",
        "def split_documents_into_chunks(docs, chunk_size=500, chunk_overlap=100):\n",
        "    \"\"\"\n",
        "    Splits the given documents into chunks of specified size with overlap.\n",
        "\n",
        "    Args:\n",
        "        docs (list): List of documents to split.\n",
        "        chunk_size (int): Size of each chunk. Default is 500 characters.\n",
        "        chunk_overlap (int): Overlap size between chunks. Default is 100 characters.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of lists containing split documents with chunks per original document.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "    doc_chunks = {}\n",
        "    for doc in docs:\n",
        "        doc_chunks[doc.metadata[\"source\"]] = text_splitter.split_documents([doc])\n",
        "    return doc_chunks\n",
        "\n",
        "def add_chunk_numbers_to_metadata(doc_chunks):\n",
        "    \"\"\"\n",
        "    Adds chunk numbers to the metadata of each split document.\n",
        "\n",
        "    Args:\n",
        "        doc_chunks (dict): Dictionary of lists containing split documents.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of lists containing split documents with updated metadata.\n",
        "    \"\"\"\n",
        "    for chunks in doc_chunks.values():\n",
        "        for idx, chunk in enumerate(chunks):\n",
        "            chunk.metadata[\"chunk\"] = idx\n",
        "    return doc_chunks\n",
        "\n",
        "def configure_faiss_vector_store(doc_splits, embeddings):\n",
        "    \"\"\"\n",
        "    Configures FAISS as the vector store using the provided document splits and embeddings.\n",
        "\n",
        "    Args:\n",
        "        doc_splits (dict): Dictionary of lists containing split documents.\n",
        "        embeddings (Embeddings): Embeddings to be used for FAISS.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of FAISS vector stores per document.\n",
        "    \"\"\"\n",
        "    vector_stores = {}\n",
        "    for doc_source, chunks in doc_splits.items():\n",
        "        vector_stores[doc_source] = FAISS.from_documents(chunks, embeddings)\n",
        "    return vector_stores\n",
        "\n",
        "def save_faiss_vector_store(vector_db, directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    for doc_source, vector_store in vector_db.items():\n",
        "        index_path = os.path.join(directory, f\"{doc_source}.index\")\n",
        "        faiss.write_index(vector_store.index, index_path)\n",
        "\n",
        "        # Save docstore and index_to_docstore_id\n",
        "        metadata_path = os.path.join(directory, f\"{doc_source}.metadata\")\n",
        "        with open(metadata_path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'docstore': vector_store.docstore,\n",
        "                'index_to_docstore_id': vector_store.index_to_docstore_id\n",
        "            }, f)\n",
        "\n",
        "def load_faiss_vector_store(directory, embedding):\n",
        "    vector_db = {}\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.index'):\n",
        "            doc_source = os.path.splitext(filename)[0]\n",
        "            index_path = os.path.join(directory, filename)\n",
        "            metadata_path = os.path.join(directory, f\"{doc_source}.metadata\")\n",
        "\n",
        "            # Load FAISS index\n",
        "            index = faiss.read_index(index_path)\n",
        "\n",
        "            # Load metadata\n",
        "            with open(metadata_path, 'rb') as f:\n",
        "                metadata = pickle.load(f)\n",
        "\n",
        "            # Reconstruct FAISS vector store\n",
        "            vector_store = FAISS(\n",
        "                embedding_function=embedding,\n",
        "                index=index,\n",
        "                docstore=metadata['docstore'],\n",
        "                index_to_docstore_id=metadata['index_to_docstore_id']\n",
        "            )\n",
        "\n",
        "            vector_db[doc_source] = vector_store\n",
        "\n",
        "    return vector_db\n",
        "\n",
        "def create_retrievers(vector_stores, search_type=\"similarity\", k=5):\n",
        "    \"\"\"\n",
        "    Exposes the vector store index to retrievers for multiple documents.\n",
        "\n",
        "    Args:\n",
        "        vector_stores (dict): Dictionary of FAISS vector stores per document.\n",
        "        search_type (str): The type of search to perform. Default is \"similarity\".\n",
        "        k (int): The number of documents to return. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of retrievers per document.\n",
        "    \"\"\"\n",
        "    retrievers = {}\n",
        "    for doc_source, vector_store in vector_stores.items():\n",
        "        retrievers[doc_source] = vector_store.as_retriever(\n",
        "            search_type=search_type, search_kwargs={\"k\": k}\n",
        "        )\n",
        "    return retrievers\n",
        "\n",
        "def process_query(query: str, retriever):\n",
        "    \"\"\"\n",
        "    Processes the query using the provided retriever to retrieve relevant document chunks.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for relevant documents.\n",
        "        retriever: The retriever object configured to use the vector store for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: A string containing the formatted content and metadata of the retrieved document chunks.\n",
        "    \"\"\"\n",
        "    # Retrieve chunks based on the query\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    # Initialize an empty string to collect all outputs\n",
        "    full_output = \"\"\n",
        "\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        chunk_output = f\"-----Chunk {i}------\\n\"\n",
        "        chunk_output += f\"Content: {doc.page_content}...\\n\"\n",
        "        chunk_output += f\"Metadata {doc.metadata}\\n\\n\"\n",
        "\n",
        "        # Append the chunk output to the full output\n",
        "        full_output += chunk_output\n",
        "\n",
        "    return full_output\n",
        "\n",
        "# without conversation history\n",
        "# def get_groq_response(client, prompt, model=\"llama3-70b-8192\", max_tokens=2048, temperature=0.0):\n",
        "#     \"\"\"\n",
        "#     Generates a response using the provided client, model, prompt, and specified parameters.\n",
        "\n",
        "#     Args:\n",
        "#         client: The client object to interact with the API.\n",
        "#         prompt (str): The prompt to generate a response for.\n",
        "#         model (str, optional): The model identifier to use for generating the response. Default is \"llama3-70b-8192\".\n",
        "#         max_tokens (int, optional): The maximum number of tokens for the generated response. Default is 2048.\n",
        "#         temperature (float, optional): The temperature setting for the response generation. Default is 0.0.\n",
        "\n",
        "#     Returns:\n",
        "#         tuple: The generated response content and usage statistics.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         chat_completion = client.chat.completions.create(\n",
        "#             messages=[\n",
        "#                 {\n",
        "#                     \"role\": \"user\",\n",
        "#                     \"content\": prompt,\n",
        "#                 }\n",
        "#             ],\n",
        "#             model=model,\n",
        "#             max_tokens=max_tokens,\n",
        "#             temperature=temperature\n",
        "#         )\n",
        "#         return chat_completion.choices[0].message.content, chat_completion.usage\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred: {e}\")\n",
        "#         return None, None\n",
        "\n",
        "\n",
        "# with conversation history\n",
        "def get_groq_response(client, prompt, conversation_history=None, model=\"llama3-70b-8192\", max_tokens=2048, temperature=0.0):\n",
        "    \"\"\"\n",
        "    Generates a response using the provided client, model, prompt, and specified parameters,\n",
        "    maintaining conversation history.\n",
        "\n",
        "    Args:\n",
        "        client: The client object to interact with the API.\n",
        "        prompt (str): The new prompt to generate a response for.\n",
        "        conversation_history (list, optional): List of previous messages in the conversation. Default is a new conversation.\n",
        "        model (str, optional): The model identifier to use for generating the response. Default is \"llama3-70b-8192\".\n",
        "        max_tokens (int, optional): The maximum number of tokens for the generated response. Default is 2048.\n",
        "        temperature (float, optional): The temperature setting for the response generation. Default is 0.0.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The generated response content, updated conversation history.\n",
        "    \"\"\"\n",
        "    if conversation_history is None:\n",
        "        conversation_history = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "\n",
        "    try:\n",
        "        # Append the new user prompt to the conversation history\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Create the chat completion with the conversation history\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=conversation_history,\n",
        "            model=model,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "\n",
        "        # Get the response content\n",
        "        response_content = chat_completion.choices[0].message.content\n",
        "\n",
        "        # Append the model's response to the conversation history\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": response_content})\n",
        "\n",
        "        return response_content, conversation_history\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, conversation_history\n",
        "\n",
        "\n",
        "def generate_prompt_hyde(instruction, user_query, context_hyde):\n",
        "    \"\"\"\n",
        "    Generates a prompt for HyDE by replacing placeholders in the instruction template with the user's query and context.\n",
        "\n",
        "    Args:\n",
        "        instruction (str): The template instruction containing placeholders.\n",
        "        user_query (str): The user's query to be inserted into the instruction.\n",
        "        context_hyde (str): The context for creating a hypothetical answer to be inserted into the instruction.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated instruction with the placeholders replaced by the user's query and context.\n",
        "    \"\"\"\n",
        "    instruction = instruction.replace(\"{USER_QUERY}\", user_query)\n",
        "    instruction = instruction.replace(\"{CONTEXT_HYDE}\", context_hyde)\n",
        "    return instruction\n",
        "\n",
        "def generate_prompt_final(instruction, user_query, context_figure_table, context_rag_hyde, context_rag_general):\n",
        "    \"\"\"\n",
        "    Generates a final prompt by replacing placeholders in the instruction template with the user's query and various contexts.\n",
        "\n",
        "    Args:\n",
        "        instruction (str): The template instruction containing placeholders.\n",
        "        user_query (str): The user's query to be inserted into the instruction.\n",
        "        context_figure_table (str): The context(description) related to figure and table to be inserted into the instruction.\n",
        "        context_rag_hyde (str): The context retreived from RAG HyDE to be inserted into the instruction.\n",
        "        context_rag_general (str): The general context retreived from RAG to be inserted into the instruction.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated instruction with the placeholders replaced by the user's query and contexts.\n",
        "    \"\"\"\n",
        "    instruction = instruction.replace(\"{USER_QUERY}\", user_query)\n",
        "    instruction = instruction.replace(\"{CONTEXT_FIGURE_TABLE}\", context_figure_table)\n",
        "    instruction = instruction.replace(\"{CONTEXT_RAG_HYDE}\", context_rag_hyde)\n",
        "    instruction = instruction.replace(\"{CONTEXT_RAG_GENERAL}\", context_rag_general)\n",
        "    return instruction\n",
        "\n",
        "def generate_prompt_extract_query(instruction, user_query):\n",
        "    \"\"\"\n",
        "    Generates a prompt for extracting keys from the user's query by replacing placeholders in the instruction template.\n",
        "\n",
        "    Args:\n",
        "        instruction (str): The template instruction containing a placeholder for the user's query.\n",
        "        user_query (str): The user's query to be inserted into the instruction.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated instruction with the placeholder replaced by the user's query.\n",
        "    \"\"\"\n",
        "    instruction = instruction.replace(\"{USER_QUERY}\", user_query)\n",
        "    return instruction\n",
        "\n",
        "def parse_and_convert_keys(json_string):\n",
        "    \"\"\"\n",
        "    Parse the JSON string and convert the string values in the keys list to their appropriate types.\n",
        "\n",
        "    Args:\n",
        "    json_string (str): A JSON string representing a list of dictionaries with string values for 'thesis', 'figure', and 'table'.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of dictionaries with 'thesis' as int, and 'figure' and 'table' as int or None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        keys = json.loads(json_string)\n",
        "        if not keys:\n",
        "            return []\n",
        "\n",
        "        converted_keys = []\n",
        "        for key in keys:\n",
        "            converted_key = {\n",
        "                \"thesis\": int(key[\"thesis\"]) if key[\"thesis\"] else None,\n",
        "                \"figure\": int(key[\"figure\"]) if key[\"figure\"] else None,\n",
        "                \"table\": int(key[\"table\"]) if key[\"table\"] else None\n",
        "            }\n",
        "            converted_keys.append(converted_key)\n",
        "        return converted_keys\n",
        "    except json.JSONDecodeError as e:\n",
        "        # print(f\"JSON decoding error: {e}\")\n",
        "        return []\n",
        "    except KeyError as e:\n",
        "        # print(f\"Missing key in JSON data: {e}\")\n",
        "        return []\n",
        "    except ValueError as e:\n",
        "        # print(f\"Value error: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        # print(f\"An unexpected error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_descriptions(df, keys):\n",
        "    \"\"\"\n",
        "    Extract and format descriptions from the dataframe based on the provided keys.\n",
        "\n",
        "    Args:\n",
        "    df (DataFrame): The dataframe containing thesis, figure, table, and description data.\n",
        "    keys (list): A list of dictionaries with 'thesis' as int, and 'figure' and 'table' as int or None.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of formatted descriptions corresponding to the provided keys.\n",
        "    \"\"\"\n",
        "    formatted_descriptions = []\n",
        "\n",
        "    for key in keys:\n",
        "        thesis_num = key[\"thesis\"]\n",
        "        figure_num = key[\"figure\"]\n",
        "        table_num = key[\"table\"]\n",
        "\n",
        "        if figure_num is not None:\n",
        "            description = df[(df[\"thesis_num\"] == thesis_num) & (df[\"figure_num\"] == figure_num)][\"description\"].values\n",
        "            prefix = f\"thesis{thesis_num} figure{figure_num} description: \"\n",
        "        elif table_num is not None:\n",
        "            description = df[(df[\"thesis_num\"] == thesis_num) & (df[\"table_num\"] == table_num)][\"description\"].values\n",
        "            prefix = f\"thesis{thesis_num} table{table_num} description: \"\n",
        "        else:\n",
        "            description = []\n",
        "            prefix = \"\"\n",
        "\n",
        "        if len(description) > 0:\n",
        "            formatted_descriptions.append(prefix + description[0])\n",
        "        else:\n",
        "            formatted_descriptions.append(prefix + \"Description not found\")\n",
        "\n",
        "    return formatted_descriptions\n",
        "\n",
        "def extract_thesis_numbers(converted_keys):\n",
        "    \"\"\"\n",
        "    Extracts the thesis numbers from a list of dictionaries.\n",
        "\n",
        "    Args:\n",
        "    converted_keys (list): A list of dictionaries with 'thesis', 'figure', and 'table' keys.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of thesis numbers.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        thesis_numbers = [item['thesis'] for item in converted_keys]\n",
        "        return thesis_numbers\n",
        "    except Exception as e:\n",
        "        # print(f\"An error occurred while extracting thesis numbers: {e}\")\n",
        "        return []\n",
        "\n",
        "def get_descriptions_for_thesis_summary(thesis_numbers, table_summary):\n",
        "    \"\"\"\n",
        "    Retrieves the descriptions for the given thesis numbers from the table_summary DataFrame.\n",
        "\n",
        "    Args:\n",
        "    thesis_numbers (list): A list of thesis numbers.\n",
        "    table_summary (pd.DataFrame): The DataFrame containing thesis numbers and their descriptions.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of descriptions corresponding to the thesis numbers, formatted to indicate which thesis each description belongs to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = []\n",
        "        for thesis_num in thesis_numbers:\n",
        "            description = table_summary.loc[table_summary['thesis_num'] == thesis_num, 'description'].values[0]\n",
        "            result.append(f\"Summary description for thesis {thesis_num}: '{description}'\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        # print(f\"An error occurred while retrieving descriptions: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtJr7Mot6hU4"
      },
      "source": [
        "## 3. Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tGYKP0lnTIXe"
      },
      "outputs": [],
      "source": [
        "# Prompts(Instructions)\n",
        "\n",
        "instruction_hyde = \"\"\"\n",
        "### Instructions ###\n",
        "You are an expert in scientific academic papers. Your task is to answer to \"Users' query\" below.　If the information in the \"Context\" below seems relevant to \"Users' query\", please refer to it.\n",
        "\n",
        "### User’s query ###\n",
        "{USER_QUERY}\n",
        "\n",
        "### Context ###\n",
        "{CONTEXT_HYDE}\n",
        "\n",
        "### Output ###\n",
        "\"\"\"\n",
        "\n",
        "instruction_final = \"\"\"\n",
        "### Instructions ###\n",
        "You are an expert in scientific academic papers. Your task is to answer to \"Users' query\" below.\n",
        "If the information in the \"Figure/Table Context\" and \"Text Context\" below seem relevant to \"Users' query\", please refer to them.\n",
        "\"Text Context\" includes several chunks from different parts of an academic paper. \"Figure/Table Context\" includes the descriptions related to figures or tables in an academic paper.\n",
        "Please refer only to the relevant contexts for your response. There is no need to include unrelated context in your response.\n",
        "If the user asks about a specific figure or table and the information is contained in the Figure/Table Context, please ensure that this information is included in your response.\n",
        "If you determine that the previous conversation history is relevant, please also refer to that information to answer the user's query, especially when the the contexts below are empty.\n",
        "If the contexts and the previous conversation history do not contain the necessary information and it is difficult to answer even with general knowledge and previous context, please respond with 'The information provided is insufficient to answer your question.　Could you please clarify your question?'.\n",
        "\n",
        "##### User’s query #####\n",
        "{USER_QUERY}\n",
        "\n",
        "\n",
        "##### Figure/Table Context #####\n",
        "{CONTEXT_FIGURE_TABLE}\n",
        "\n",
        "##### Text Context #####\n",
        "{CONTEXT_RAG_HYDE}\n",
        "\n",
        "{CONTEXT_RAG_GENERAL}\n",
        "\n",
        "\n",
        "##### Output #####\n",
        "\"\"\"\n",
        "\n",
        "instruction_extract_query = \"\"\"\n",
        "### Instructions ###\n",
        "You are an NLP engineer. Your task is to extract the \"numbers\" from the user's query below.\n",
        "The \"numbers\" mean which academic paper the user is referring to, 2) which figure the user is referring to, and 3) which table the user is referring to.\n",
        "There may be cases where all, some, or none of these are specified. Enter the number only for the specified fields, and return an empty string \"\" for fields that are not specified.\n",
        "Interpret \"figure\" for terms such as \"Chart,\" \"Diagram,\" or \"Image.\" Interpret \"thesis\" for terms such as \"Academic Paper,\" \"Paper,\" or \"Document.\"\n",
        "Please provide your response as a list of objects, each containing thesis, figure, and table.　Please provide your response strictly in the specified format, without including any additional text for formatting. I will use your response directly.\n",
        "If it is unclear which thesis, figure, or table is being referred to, it is okay to return an empty string. Please do not make any assumptions.\n",
        "\n",
        "### Output Format ###\n",
        "Format: a list of objects\n",
        "\n",
        "### Example user's query1 ###\n",
        "What is the main hypothesis or research question addressed in the first academic article?\n",
        "\n",
        "### Example Output1 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"1\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query2 ###\n",
        "Summarize the methodology used in the third academic article. Highlight any unique approaches or techniques employed.\n",
        "\n",
        "### Example Output2 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"3\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "\n",
        "### Example user's query3 ###\n",
        "Q. From the images and figures in the second article, describe the trend shown in Figure 2. What does it indicate about the research findings?\n",
        "\n",
        "### Example Output3 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"2\",\n",
        "  \"figure\": \"2\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query4 ###\n",
        "Q. What can be understood from Image 3 in the third paper?\n",
        "\n",
        "### Example Output4 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"3\",\n",
        "  \"figure\": \"3\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query4 ###\n",
        "Q. Please explain Figure 3 and Table 2 of the second academic paper. What do these indicate about the research findings?\n",
        "\n",
        "### Example Output4 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"2\",\n",
        "  \"figure\": \"3\",\n",
        "  \"table\": \"\"\n",
        "  },\n",
        "  {\n",
        "  \"thesis\": \"2\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"2\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query5 ###\n",
        "Q. Please compare table 3 and chart 4 from the second and third theses, respectively.\n",
        "\n",
        "### Example Output5 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"2\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"3\"\n",
        "  },\n",
        "  {\n",
        "  \"thesis\": \"3\",\n",
        "  \"figure\": \"4\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query6 ###\n",
        "Do you like an apple?\n",
        "\n",
        "### Example Output6 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "### Example user's query7 ###\n",
        "Considering the previous conversations, please propose a new research direction or hypothesis.\n",
        "\n",
        "### Example Output7 ###\n",
        "[\n",
        "  {\n",
        "  \"thesis\": \"\",\n",
        "  \"figure\": \"\",\n",
        "  \"table\": \"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "\n",
        "### User’s query ###\n",
        "{USER_QUERY}\n",
        "\n",
        "### Output ###\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_D6noSE6pP-"
      },
      "source": [
        "## 4. Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkq63-IQ7pIo"
      },
      "source": [
        "### 4-1. Creating VectorDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "deddb541c492437783713a5e745fcf1f",
            "582a4ddd2d6245fab5448915dfdc023c",
            "4965f1b2df6d4d5db4c4c1a459c18e2f",
            "ae43b71c52424a1f91ca075af1d8f7c2",
            "0885cfcaeca94730b8a30dfb9be5a1f0",
            "15359c2a0f4042168643371bf807114a",
            "7bfc284b84234b76ab6ba1e386cb9ee4",
            "d16ceae53e20454d81791ff98e6ac2ab",
            "bf1e3512da0f49b88447efb2c687e071",
            "d1c4dcdb15064bf2afe5236fee5c927c",
            "daebd4e8a5d24bee981d05c920d7fc34",
            "ad29fb5516714b0fb0e078ac30f10f6a",
            "c8048c7f738c41aeb13aa74738b780b7",
            "c65fab8b56784975919132108788d293",
            "579566a268594ba2b068a800e163162d",
            "12946a90ce0c4a8fbae2904ae0ed724e",
            "c6f7f06d48b24059bbd204a0b11a8790",
            "ecdefab2489f466fa13cc8d56029ac19",
            "53c7a338bf5a48d1b14f009d715c3b41",
            "86fd3639bef7421c87f98b8f3f9607bc",
            "fd6591283ac8426a9b50414a9b81235b",
            "27dddaf968104e69bea3caaeecf21dd4",
            "eeb9f3f5ceae4cd9b362e760fc890adf",
            "3954e36c844b4f2e817b2346542b4700",
            "ad245e545dfd4c3194fcbd6e3b5a69e0",
            "06d7d1fb506e42f8ae155ab9f108beb1",
            "c21183ba2d7345fd8c81646cc47638a1",
            "2aaaef23901d4c9e8c680112f8cd2ee2",
            "90eeb8a7ed254bd4a324bb2546cc5573",
            "afd4375c57b84dedbd0d6e285e1eaed6",
            "f4ce906f42ff4a90b62276b1a87e90b4",
            "75873830e9da4a9a9a4cd2bc46b74a60",
            "f1e59fd075c8443e86f3d9fabe7a49d5"
          ]
        },
        "id": "oCzy_vdYTdVT",
        "outputId": "d8ffb40f-7522-4d44-ca5f-4709835e2d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deddb541c492437783713a5e745fcf1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad29fb5516714b0fb0e078ac30f10f6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/228k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eeb9f3f5ceae4cd9b362e760fc890adf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Creating VectorDB\n",
        "# Load PDFs\n",
        "pdf_paths = [\"attention.pdf\", \"Multimodal.pdf\"] # Change it to YOUR PATH\n",
        "\n",
        "# Extract text from each PDF and create Document objects\n",
        "docs = extract_texts_from_pdfs(pdf_paths)\n",
        "\n",
        "## Chunk\n",
        "# Split the documents into chunks\n",
        "doc_splits = split_documents_into_chunks(docs)\n",
        "# Add chunk number to metadata\n",
        "doc_splits = add_chunk_numbers_to_metadata(doc_splits)\n",
        "\n",
        "## Embedding\n",
        "# SciBERT(Allen Institute for AI) - for academic(science) paper including computer science\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"allenai/scibert_scivocab_uncased\")\n",
        "\n",
        "## Vector Store\n",
        "# Configure FAISS as Vector Store\n",
        "vector_db = configure_faiss_vector_store(doc_splits, embeddings)\n",
        "\n",
        "# Save the vector_db\n",
        "vectordb_path = \"vectordb_faiss\" # Change it to YOUR PATH\n",
        "save_faiss_vector_store(vector_db, vectordb_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVygFqp272wg"
      },
      "source": [
        "### 4-2. Creating Image/Table Desctiption Table"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/daichi6/llm-hackathon-insightai/blob/main/notebooks/image_description_generation.ipynb"
      ],
      "metadata": {
        "id": "w6nz3sfIaDA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating Figure/Table Descriptions\n",
        "- Extracting Figure/Table Numbers from Images using LLM\n",
        "- Combining them into a Final Table"
      ],
      "metadata": {
        "id": "P_U9k1oFaFnI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiqnksVZ8L54"
      },
      "source": [
        "### 4-3. Creating Summary Table"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/daichi6/llm-hackathon-insightai/blob/main/notebooks/summary_table_generation.ipynb"
      ],
      "metadata": {
        "id": "6ZzVDDd9affF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating summaries for each academic paper"
      ],
      "metadata": {
        "id": "wl2fIQ-Uahqi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIYnVSBb7AeK"
      },
      "source": [
        "## 5. Load prepared data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv0eAE5o8cCq"
      },
      "source": [
        "### 5-1. Load VectorDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WhW-IrYM7ZQx"
      },
      "outputs": [],
      "source": [
        "## Load prepared vectorDB\n",
        "# Load the vector_db\n",
        "vector_db = load_faiss_vector_store(vectordb_path, embeddings)\n",
        "# Create retrievers for each document and store them in a dictionary\n",
        "retrievers = create_retrievers(vector_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOdoAqLC8fuy"
      },
      "source": [
        "### 5-2. Load Image/Table Desctiption Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Adq-rtgv7C6V"
      },
      "outputs": [],
      "source": [
        "## Load prepared tables\n",
        "table_figure_table = pd.read_csv(\"image_analysis_results.csv\") # Change it to YOUR PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9qvmZYX8jo3"
      },
      "source": [
        "### 5-3. Load Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5d-WbgiD8kxi"
      },
      "outputs": [],
      "source": [
        "# Load table with thesis_num and description\n",
        "table_summary = pd.read_csv(\"summaries.csv\") # Change it to YOUR PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdIrzw0j6snA"
      },
      "source": [
        "## 6. Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iPq1fnTHCORS"
      },
      "outputs": [],
      "source": [
        "## User selection\n",
        "# User thesis selection before asking questions\n",
        "pdf_paths_user_selected = [\"attention.pdf\", \"Multimodal.pdf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "17XIY37dcj1a"
      },
      "outputs": [],
      "source": [
        "# LLM for the main flow\n",
        "client_main = Groq(\n",
        "    api_key=\"YOUR_API_KEY_1\",\n",
        ")\n",
        "#  LLM for keys(thesis/figure/table) extaction\n",
        "client_extract = Groq(\n",
        "    api_key=\"YOUR_API_KEY_2\",\n",
        ")\n",
        "# LLM for HyDE\n",
        "client_hyde = Groq(\n",
        "    api_key=\"YOUR_API_KEY_3\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-KOsa_idg_2_"
      },
      "outputs": [],
      "source": [
        "# Main\n",
        "\n",
        "def chat_main(user_query, conversation_history):\n",
        "\n",
        "  ## 1. extract keys from user's query and find figure/table description and summary description ##\n",
        "  # generate prompt to extract keys from user's query\n",
        "  prompt_extract_query = generate_prompt_extract_query(instruction_extract_query, user_query)\n",
        "  # get keys from Extraction LLM\n",
        "  response_keys = get_groq_response(client = client_extract, prompt = prompt_extract_query)\n",
        "\n",
        "  # parse keys\n",
        "  keys = parse_and_convert_keys(response_keys[0])\n",
        "\n",
        "  # extract figure/table descriptions\n",
        "  descriptions_figure_table = extract_descriptions(table_figure_table, keys)\n",
        "\n",
        "  # extract thesis numbers from keys\n",
        "  keys_thesis = extract_thesis_numbers(keys)\n",
        "  # get summary descriptions\n",
        "  descriptions_summary = get_descriptions_for_thesis_summary(keys_thesis, table_summary)\n",
        "\n",
        "  ## 2. get context for HyDE and general RAG ##\n",
        "  # add summary of the thesis as a context for HyDE\n",
        "  context_hyde = descriptions_summary\n",
        "  # create prompt for HyDE\n",
        "  prompt_hyde = generate_prompt_hyde(instruction_hyde, user_query, str(context_hyde))\n",
        "  # get a hypothetical answer from HyDE LLM\n",
        "  response_hyde = get_groq_response(client = client_hyde, prompt = prompt_hyde)\n",
        "\n",
        "  # # create contexts\n",
        "  # initialize empty strings for contexts\n",
        "  context_rag_hyde = \"\"\n",
        "  context_rag_general = \"\"\n",
        "\n",
        "  # search for documents based on keys_thesis(thesis number extracted from user's query)\n",
        "  if keys_thesis and all(key is not None for key in keys_thesis):\n",
        "      for key in keys_thesis:\n",
        "          if isinstance(key, int):\n",
        "              adjusted_key = key - 1  # adjust the key by subtracting 1\n",
        "              doc_source = pdf_paths_user_selected[adjusted_key]  # get the document source(FROM USER'S SELECTED LISTS) based on the adjusted key\n",
        "              retriever = retrievers[doc_source]  # get the corresponding retriever\n",
        "\n",
        "              # process query for RAG(Hyde)\n",
        "              result_hyde = process_query(response_hyde[0], retriever)\n",
        "              context_rag_hyde += f\"Document {key}:\\n{result_hyde}\\n\"\n",
        "\n",
        "              # process query for RAG(General)\n",
        "              result_general = process_query(user_query, retriever)\n",
        "              context_rag_general += f\"Document {key}:\\n{result_general}\\n\"\n",
        "  else:\n",
        "      context_rag_hyde = \"\"\n",
        "      context_rag_general = \"\"\n",
        "\n",
        "  ## 3. get a final response ##\n",
        "  # create prompt for a final response\n",
        "  prompt_final = generate_prompt_final(instruction_final, user_query, str(descriptions_figure_table), context_rag_hyde, context_rag_general)\n",
        "  # get final response from main LLM\n",
        "  response_final = get_groq_response(client = client_main, prompt = prompt_final, conversation_history = conversation_history)\n",
        "\n",
        "  return response_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_h3T7q64Td"
      },
      "source": [
        "## 7. Asking questions - test cases for conversation history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the conversation history list\n",
        "conversation_history_list = []"
      ],
      "metadata": {
        "id": "qtEk_jPrIoaR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgIMCtwd3R7t",
        "outputId": "a23c8b33-5cf7-4751-9e7f-368e6eb30f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 1 in the first academic paper compares the computational complexity of different neural network layer types commonly used in sequence modeling tasks. The table has 4 columns (Layer Type, Complexity per Layer, Sequential Operations, Maximum Path Length) and 4 rows corresponding to different layer types (Self-Attention, Recurrent, Convolutional, Self-Attention (restricted)). \n",
            "\n",
            "The table shows that Self-Attention layers have O(n^2 · d) complexity per layer, Recurrent layers have O(n · d^2) complexity, Convolutional layers have O(k · n · d^2) complexity, and restricting the self-attention to a neighborhood of size r reduces complexity to O(r · n · d). In terms of sequential operations, self-attention and convolutions require O(1) sequential operations while recurrent layers require O(n). \n",
            "\n",
            "This table provides valuable insights for designing efficient neural network architectures, highlighting the scalability advantages of self-attention and convolutional layers over recurrent layers.\n"
          ]
        }
      ],
      "source": [
        "# table description test\n",
        "user_query = 'Can you explain the table 1 in the first academic paper?'\n",
        "# get response\n",
        "response = chat_main(user_query, conversation_history_list)\n",
        "# update conversation history\n",
        "conversation_history_list = response[1]\n",
        "# print response\n",
        "print(response[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conversation history test\n",
        "user_query = 'Could you give a more concise answer?'\n",
        "# get response\n",
        "response = chat_main(user_query, conversation_history_list)\n",
        "# update conversation history\n",
        "conversation_history_list = response[1]\n",
        "# print response\n",
        "print(response[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fd61QQJJRrq",
        "outputId": "f8121561-a4f4-4780-8bd0-55bb1b7bbe28"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a more concise answer:\n",
            "\n",
            "Table 1 compares the computational complexity of different neural network layer types (Self-Attention, Recurrent, Convolutional, and restricted Self-Attention) for sequence modeling tasks, highlighting their scalability advantages.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "deddb541c492437783713a5e745fcf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_582a4ddd2d6245fab5448915dfdc023c",
              "IPY_MODEL_4965f1b2df6d4d5db4c4c1a459c18e2f",
              "IPY_MODEL_ae43b71c52424a1f91ca075af1d8f7c2"
            ],
            "layout": "IPY_MODEL_0885cfcaeca94730b8a30dfb9be5a1f0"
          }
        },
        "582a4ddd2d6245fab5448915dfdc023c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15359c2a0f4042168643371bf807114a",
            "placeholder": "​",
            "style": "IPY_MODEL_7bfc284b84234b76ab6ba1e386cb9ee4",
            "value": "config.json: 100%"
          }
        },
        "4965f1b2df6d4d5db4c4c1a459c18e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16ceae53e20454d81791ff98e6ac2ab",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf1e3512da0f49b88447efb2c687e071",
            "value": 385
          }
        },
        "ae43b71c52424a1f91ca075af1d8f7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1c4dcdb15064bf2afe5236fee5c927c",
            "placeholder": "​",
            "style": "IPY_MODEL_daebd4e8a5d24bee981d05c920d7fc34",
            "value": " 385/385 [00:00&lt;00:00, 19.1kB/s]"
          }
        },
        "0885cfcaeca94730b8a30dfb9be5a1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15359c2a0f4042168643371bf807114a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfc284b84234b76ab6ba1e386cb9ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d16ceae53e20454d81791ff98e6ac2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1e3512da0f49b88447efb2c687e071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1c4dcdb15064bf2afe5236fee5c927c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daebd4e8a5d24bee981d05c920d7fc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad29fb5516714b0fb0e078ac30f10f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8048c7f738c41aeb13aa74738b780b7",
              "IPY_MODEL_c65fab8b56784975919132108788d293",
              "IPY_MODEL_579566a268594ba2b068a800e163162d"
            ],
            "layout": "IPY_MODEL_12946a90ce0c4a8fbae2904ae0ed724e"
          }
        },
        "c8048c7f738c41aeb13aa74738b780b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f7f06d48b24059bbd204a0b11a8790",
            "placeholder": "​",
            "style": "IPY_MODEL_ecdefab2489f466fa13cc8d56029ac19",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c65fab8b56784975919132108788d293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c7a338bf5a48d1b14f009d715c3b41",
            "max": 442221694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86fd3639bef7421c87f98b8f3f9607bc",
            "value": 442221694
          }
        },
        "579566a268594ba2b068a800e163162d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd6591283ac8426a9b50414a9b81235b",
            "placeholder": "​",
            "style": "IPY_MODEL_27dddaf968104e69bea3caaeecf21dd4",
            "value": " 442M/442M [00:07&lt;00:00, 41.5MB/s]"
          }
        },
        "12946a90ce0c4a8fbae2904ae0ed724e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f7f06d48b24059bbd204a0b11a8790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdefab2489f466fa13cc8d56029ac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c7a338bf5a48d1b14f009d715c3b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fd3639bef7421c87f98b8f3f9607bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd6591283ac8426a9b50414a9b81235b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27dddaf968104e69bea3caaeecf21dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeb9f3f5ceae4cd9b362e760fc890adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3954e36c844b4f2e817b2346542b4700",
              "IPY_MODEL_ad245e545dfd4c3194fcbd6e3b5a69e0",
              "IPY_MODEL_06d7d1fb506e42f8ae155ab9f108beb1"
            ],
            "layout": "IPY_MODEL_c21183ba2d7345fd8c81646cc47638a1"
          }
        },
        "3954e36c844b4f2e817b2346542b4700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aaaef23901d4c9e8c680112f8cd2ee2",
            "placeholder": "​",
            "style": "IPY_MODEL_90eeb8a7ed254bd4a324bb2546cc5573",
            "value": "vocab.txt: 100%"
          }
        },
        "ad245e545dfd4c3194fcbd6e3b5a69e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd4375c57b84dedbd0d6e285e1eaed6",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4ce906f42ff4a90b62276b1a87e90b4",
            "value": 227845
          }
        },
        "06d7d1fb506e42f8ae155ab9f108beb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75873830e9da4a9a9a4cd2bc46b74a60",
            "placeholder": "​",
            "style": "IPY_MODEL_f1e59fd075c8443e86f3d9fabe7a49d5",
            "value": " 228k/228k [00:00&lt;00:00, 1.75MB/s]"
          }
        },
        "c21183ba2d7345fd8c81646cc47638a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aaaef23901d4c9e8c680112f8cd2ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90eeb8a7ed254bd4a324bb2546cc5573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd4375c57b84dedbd0d6e285e1eaed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ce906f42ff4a90b62276b1a87e90b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75873830e9da4a9a9a4cd2bc46b74a60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e59fd075c8443e86f3d9fabe7a49d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}